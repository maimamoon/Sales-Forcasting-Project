{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1581c9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-28T11:32:53.296258Z",
     "iopub.status.busy": "2025-04-28T11:32:53.295830Z",
     "iopub.status.idle": "2025-04-28T11:32:55.563312Z",
     "shell.execute_reply": "2025-04-28T11:32:55.562258Z"
    },
    "papermill": {
     "duration": 2.272699,
     "end_time": "2025-04-28T11:32:55.565071",
     "exception": false,
     "start_time": "2025-04-28T11:32:53.292372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/store-sales-time-series-forecasting/oil.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/stores.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/train.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/test.csv\n",
      "/kaggle/input/store-sales-time-series-forecasting/transactions.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afee95a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T11:32:55.570527Z",
     "iopub.status.busy": "2025-04-28T11:32:55.570079Z",
     "iopub.status.idle": "2025-04-28T11:52:18.265335Z",
     "shell.execute_reply": "2025-04-28T11:52:18.264218Z"
    },
    "papermill": {
     "duration": 1162.699813,
     "end_time": "2025-04-28T11:52:18.267065",
     "exception": false,
     "start_time": "2025-04-28T11:32:55.567252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1623714870.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.fillna(-1, inplace=True)\n",
      "/tmp/ipykernel_13/1623714870.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.fillna(-1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\ttraining's rmse: 0.374564\tvalid_1's rmse: 0.375972\n",
      "[1000]\ttraining's rmse: 0.362269\tvalid_1's rmse: 0.372369\n",
      "[1500]\ttraining's rmse: 0.355273\tvalid_1's rmse: 0.370785\n",
      "[2000]\ttraining's rmse: 0.350275\tvalid_1's rmse: 0.370003\n",
      "[2500]\ttraining's rmse: 0.346521\tvalid_1's rmse: 0.369552\n",
      "[3000]\ttraining's rmse: 0.343396\tvalid_1's rmse: 0.369444\n",
      "[3500]\ttraining's rmse: 0.340539\tvalid_1's rmse: 0.369198\n",
      "[4000]\ttraining's rmse: 0.337966\tvalid_1's rmse: 0.369017\n",
      "[4500]\ttraining's rmse: 0.335471\tvalid_1's rmse: 0.36897\n",
      "Early stopping, best iteration is:\n",
      "[4295]\ttraining's rmse: 0.336486\tvalid_1's rmse: 0.3689\n",
      "Validation RMSLE: 0.36889\n",
      "âœ… Submission file created successfully brother (Optimized)!\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- Load the Data ---\n",
    "train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv', parse_dates=['date'])\n",
    "test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv', parse_dates=['date'])\n",
    "\n",
    "# --- Feature Engineering Functions ---\n",
    "def create_date_features(df):\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week.astype('int')\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "    df['is_month_start'] = df['date'].dt.is_month_start.astype(int)\n",
    "    df['is_month_end'] = df['date'].dt.is_month_end.astype(int)\n",
    "    return df\n",
    "\n",
    "def create_lag_features(df, lags=[1, 7, 14, 28]):\n",
    "    for lag in lags:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(lag)\n",
    "    return df\n",
    "\n",
    "def create_rolling_features(df, windows=[7, 14, 28]):\n",
    "    for window in windows:\n",
    "        df[f'sales_roll_mean_{window}'] = df.groupby(['store_nbr', 'family'])['sales'].shift(1).rolling(window=window).mean()\n",
    "    return df\n",
    "\n",
    "# --- Label Encoding ---\n",
    "le = LabelEncoder()\n",
    "train['family'] = le.fit_transform(train['family'])\n",
    "test['family'] = le.transform(test['family'])\n",
    "\n",
    "# --- Merge train and test for feature engineering ---\n",
    "test['sales'] = np.nan  # Dummy sales column\n",
    "all_data = pd.concat([train, test], axis=0).sort_values(['store_nbr', 'family', 'date'])\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "all_data = create_date_features(all_data)\n",
    "all_data = create_lag_features(all_data)\n",
    "all_data = create_rolling_features(all_data)\n",
    "\n",
    "# --- Split back ---\n",
    "train = all_data[~all_data['sales'].isna()]\n",
    "test = all_data[all_data['sales'].isna()]\n",
    "\n",
    "# --- Fill missing ---\n",
    "train.fillna(-1, inplace=True)\n",
    "test.fillna(-1, inplace=True)\n",
    "\n",
    "# --- Prepare Features and Target ---\n",
    "features = [\n",
    "    'store_nbr', 'family', 'onpromotion', 'day', 'weekofyear', 'month', 'year', 'dayofweek',\n",
    "    'is_weekend', 'is_month_start', 'is_month_end',\n",
    "    'sales_lag_1', 'sales_lag_7', 'sales_lag_14', 'sales_lag_28',\n",
    "    'sales_roll_mean_7', 'sales_roll_mean_14', 'sales_roll_mean_28'\n",
    "]\n",
    "\n",
    "target = 'sales'\n",
    "\n",
    "# --- Train-Validation Split ---\n",
    "X_train = train[train['date'] < '2017-07-01'][features]\n",
    "y_train = train[train['date'] < '2017-07-01'][target]\n",
    "X_valid = train[train['date'] >= '2017-07-01'][features]\n",
    "y_valid = train[train['date'] >= '2017-07-01'][target]\n",
    "\n",
    "# --- Important Trick: Log Transform Target ---\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_valid_log = np.log1p(y_valid)\n",
    "\n",
    "# --- LightGBM Dataset ---\n",
    "train_data = lgb.Dataset(X_train, label=y_train_log, categorical_feature=['family'])\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid_log, categorical_feature=['family'])\n",
    "\n",
    "# --- LightGBM Parameters ---\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.02,\n",
    "    'num_leaves': 256,\n",
    "    'max_depth': 8,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 1,\n",
    "    'lambda_l2': 1,\n",
    "    'seed': 42,\n",
    "    'verbosity': -1,\n",
    "}\n",
    "\n",
    "# --- Train the Model ---\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, valid_data],\n",
    "    num_boost_round=20000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=300),\n",
    "        lgb.log_evaluation(period=500)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Validation RMSLE ---\n",
    "y_pred_valid_log = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "y_pred_valid = np.expm1(y_pred_valid_log)  # Inverse transform\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, np.maximum(0, y_pred)))\n",
    "\n",
    "print(f'Validation RMSLE: {rmsle(y_valid, y_pred_valid):.5f}')\n",
    "\n",
    "# --- Predict on Test Set ---\n",
    "X_test = test[features]\n",
    "y_test_pred_log = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_test_pred = np.expm1(y_test_pred_log)  # Inverse transform\n",
    "y_test_pred = np.maximum(0, y_test_pred)\n",
    "\n",
    "# --- Submission ---\n",
    "submission = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/sample_submission.csv')\n",
    "submission['sales'] = y_test_pred\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"âœ… Submission file created successfully brother (Optimized)!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1171.461739,
   "end_time": "2025-04-28T11:52:19.394228",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-28T11:32:47.932489",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
